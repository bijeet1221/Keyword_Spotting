{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport torch\nimport torchaudio\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchaudio.datasets import SPEECHCOMMANDS\nimport torchaudio.transforms as transforms\nimport torchvision.models as models\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as Func","metadata":{"execution":{"iopub.status.busy":"2024-09-05T16:50:12.389584Z","iopub.execute_input":"2024-09-05T16:50:12.390167Z","iopub.status.idle":"2024-09-05T16:50:12.396165Z","shell.execute_reply.started":"2024-09-05T16:50:12.390118Z","shell.execute_reply":"2024-09-05T16:50:12.395150Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"# Define the dataset path\ndataset_path = \"./data/speech_commands\"\n\n# Ensure the directory exists\nos.makedirs(dataset_path, exist_ok=True)\n\n# Download and extract the dataset\ntorchaudio.datasets.SPEECHCOMMANDS(root=dataset_path, download=True)","metadata":{"execution":{"iopub.status.busy":"2024-09-05T16:25:36.451408Z","iopub.execute_input":"2024-09-05T16:25:36.451818Z","iopub.status.idle":"2024-09-05T16:25:37.075965Z","shell.execute_reply.started":"2024-09-05T16:25:36.451780Z","shell.execute_reply":"2024-09-05T16:25:37.074941Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"<torchaudio.datasets.speechcommands.SPEECHCOMMANDS at 0x79653a4e0820>"},"metadata":{}}]},{"cell_type":"code","source":"class SubsetSC(SPEECHCOMMANDS):\n    def __init__(self, subset: str = None, classes=None):\n        super().__init__(\"./data/speech_commands\", download=False)\n        \n        def load_list(filename):\n            with open(filename) as f:\n                return [os.path.join(self._path, line.strip()) for line in f]\n        \n        if subset == \"validation\":\n            self._walker = load_list(self._path + \"/validation_list.txt\")\n        elif subset == \"testing\":\n            self._walker = load_list(self._path + \"/testing_list.txt\")\n        elif subset == \"training\":\n            excludes = load_list(self._path + \"/validation_list.txt\") + load_list(self._path + \"/testing_list.txt\")\n            excludes = set(excludes)\n            self._walker = [w for w in self._walker if w not in excludes]\n        \n        # Select only \"yes\" and \"no\" classes\n        self.classes = classes if classes else ['yes', 'no']\n\n    def __getitem__(self, index):\n        waveform, sample_rate, label, *_ = super().__getitem__(index)\n        \n        # Ensure the label is in 'yes' or 'no'\n        if label not in self.classes:\n            return None  # Skip if it's not in 'yes' or 'no'\n        \n        # Pad or truncate the waveform\n        waveform = self.pad_or_truncate_waveform(waveform)\n        \n        # Convert label to index\n        label_idx = self.classes.index(label)\n        \n        return waveform, label_idx\n\n    # Pad or truncate waveforms to a fixed length (e.g., 16000 for 1 second at 16 kHz)\n    # Different audio files have differnet lengths\n    # Therefore it is necessary to convert every file to same dimension\n    def pad_or_truncate_waveform(self, waveform, target_length=16000):\n        length = waveform.shape[-1] # length of number of samples\n        if length > target_length:\n            waveform = waveform[:, :target_length]  # Truncate\n        elif length < target_length:\n            padding = target_length - length\n            waveform = Func.pad(waveform, (0, padding))  # Pad with zeros\n        return waveform","metadata":{"execution":{"iopub.status.busy":"2024-09-05T17:08:51.133286Z","iopub.execute_input":"2024-09-05T17:08:51.134088Z","iopub.status.idle":"2024-09-05T17:08:51.146022Z","shell.execute_reply.started":"2024-09-05T17:08:51.134022Z","shell.execute_reply":"2024-09-05T17:08:51.144870Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"# Reload the dataset\ntrain_set = SubsetSC(\"training\", classes=['yes', 'no'])\nval_set = SubsetSC(\"validation\", classes=['yes', 'no'])\ntest_set = SubsetSC(\"testing\", classes=['yes', 'no'])\n\n# Remove None items\ntrain_set = [item for item in train_set if item]\nval_set = [item for item in val_set if item]\ntest_set = [item for item in test_set if item]\n\ntrain_loader = DataLoader(train_set, batch_size=64, shuffle=True)\nval_loader = DataLoader(val_set, batch_size=64, shuffle=False)\ntest_loader = DataLoader(test_set, batch_size=64, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-09-05T16:32:26.689090Z","iopub.execute_input":"2024-09-05T16:32:26.689841Z","iopub.status.idle":"2024-09-05T16:39:01.735012Z","shell.execute_reply.started":"2024-09-05T16:32:26.689795Z","shell.execute_reply":"2024-09-05T16:39:01.733932Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"mel_spectrogram = transforms.MelSpectrogram(sample_rate=16000, # sample rate\n                                            n_mels=128, # number of Mel filter banks to apply\n                                            n_fft=1024, # Window size of FFT\n                                            hop_length=512) # # The number of samples between successive frames\n\ndef transform_waveform(waveform):\n    mel_spectrogram.to(waveform.device)\n    return mel_spectrogram(waveform).log2()","metadata":{"execution":{"iopub.status.busy":"2024-09-05T17:08:54.508328Z","iopub.execute_input":"2024-09-05T17:08:54.508752Z","iopub.status.idle":"2024-09-05T17:08:54.516299Z","shell.execute_reply.started":"2024-09-05T17:08:54.508705Z","shell.execute_reply":"2024-09-05T17:08:54.515382Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"# Load the pre-trained ResNet model\nmodel = models.resnet18(pretrained=True)\n\n# Modify the first convolution layer to accept 1-channel input\nmodel.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n\nmodel = model.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-09-05T17:09:08.753543Z","iopub.execute_input":"2024-09-05T17:09:08.754421Z","iopub.status.idle":"2024-09-05T17:09:09.008792Z","shell.execute_reply.started":"2024-09-05T17:09:08.754379Z","shell.execute_reply":"2024-09-05T17:09:09.007783Z"},"trusted":true},"execution_count":63,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Loss function\ncriterion = nn.CrossEntropyLoss()\n\n# Optimizer\noptimizer = optim.Adam(model.parameters(), lr=0.001)","metadata":{"execution":{"iopub.status.busy":"2024-09-05T16:41:07.615985Z","iopub.execute_input":"2024-09-05T16:41:07.616372Z","iopub.status.idle":"2024-09-05T16:41:07.621651Z","shell.execute_reply.started":"2024-09-05T16:41:07.616334Z","shell.execute_reply":"2024-09-05T16:41:07.620730Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"markdown","source":"# ModelV0","metadata":{}},{"cell_type":"code","source":"# Training loop\ndef train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10):\n    for epoch in range(num_epochs):\n        model.train()  # Set model to training mode\n        running_loss = 0.0\n        correct = 0\n        total = 0\n\n        # Iterate over the training data\n        for waveforms, labels in train_loader:\n            waveforms, labels = waveforms.to(device), labels.to(device)\n\n            # Pad or truncate the waveforms\n            waveforms = torch.stack([pad_or_truncate_waveform(w) for w in waveforms])\n\n            # Transform the waveforms to Mel Spectrograms\n            mel_specs = torch.stack([transform_waveform(w) for w in waveforms])\n\n            # Zero the gradients\n            optimizer.zero_grad()\n\n            # Forward pass\n            outputs = model(mel_specs)\n\n            # Calculate loss\n            loss = criterion(outputs, labels)\n\n            # Backward pass and optimize\n            loss.backward()\n            optimizer.step()\n\n            # Track loss and accuracy\n            running_loss += loss.item()\n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n        # Validation step\n        val_loss, val_accuracy = evaluate_model(model, val_loader, criterion)\n        \n        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}, \"\n              f\"Accuracy: {100 * correct / total:.2f}%, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%\")\n    \n    print(\"Training complete!\")","metadata":{"execution":{"iopub.status.busy":"2024-09-05T16:41:08.981071Z","iopub.execute_input":"2024-09-05T16:41:08.981817Z","iopub.status.idle":"2024-09-05T16:41:08.991740Z","shell.execute_reply.started":"2024-09-05T16:41:08.981776Z","shell.execute_reply":"2024-09-05T16:41:08.990893Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"# Evaluation function for validation/testing\ndef evaluate_model(model, loader, criterion):\n    model.eval()  # Set model to evaluation mode\n    correct = 0\n    total = 0\n    val_loss = 0.0\n    with torch.no_grad():\n        for waveforms, labels in loader:\n            waveforms, labels = waveforms.to(device), labels.to(device)\n\n            # Pad or truncate the waveforms\n            waveforms = torch.stack([pad_or_truncate_waveform(w) for w in waveforms])\n\n            # Transform the waveforms to Mel Spectrograms\n            mel_specs = torch.stack([transform_waveform(w) for w in waveforms])\n\n            # Forward pass\n            outputs = model(mel_specs)\n            loss = criterion(outputs, labels)\n            val_loss += loss.item()\n\n            # Track accuracy\n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    accuracy = 100 * correct / total\n    return val_loss / len(loader), accuracy","metadata":{"execution":{"iopub.status.busy":"2024-09-05T16:41:09.655006Z","iopub.execute_input":"2024-09-05T16:41:09.655363Z","iopub.status.idle":"2024-09-05T16:41:09.663415Z","shell.execute_reply.started":"2024-09-05T16:41:09.655330Z","shell.execute_reply":"2024-09-05T16:41:09.662452Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"# Train the model\ntrain_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=20)","metadata":{"execution":{"iopub.status.busy":"2024-09-05T16:41:10.474601Z","iopub.execute_input":"2024-09-05T16:41:10.475478Z","iopub.status.idle":"2024-09-05T16:42:16.061563Z","shell.execute_reply.started":"2024-09-05T16:41:10.475409Z","shell.execute_reply":"2024-09-05T16:42:16.060634Z"},"trusted":true},"execution_count":57,"outputs":[{"name":"stdout","text":"Epoch [1/10], Loss: nan, Accuracy: 50.64%, Val Loss: nan, Val Accuracy: 49.44%\nEpoch [2/10], Loss: nan, Accuracy: 50.64%, Val Loss: nan, Val Accuracy: 49.44%\nEpoch [3/10], Loss: nan, Accuracy: 50.64%, Val Loss: nan, Val Accuracy: 49.44%\nEpoch [4/10], Loss: nan, Accuracy: 50.64%, Val Loss: nan, Val Accuracy: 49.44%\nEpoch [5/10], Loss: nan, Accuracy: 50.64%, Val Loss: nan, Val Accuracy: 49.44%\nEpoch [6/10], Loss: nan, Accuracy: 50.64%, Val Loss: nan, Val Accuracy: 49.44%\nEpoch [7/10], Loss: nan, Accuracy: 50.64%, Val Loss: nan, Val Accuracy: 49.44%\nEpoch [8/10], Loss: nan, Accuracy: 50.64%, Val Loss: nan, Val Accuracy: 49.44%\nEpoch [9/10], Loss: nan, Accuracy: 50.64%, Val Loss: nan, Val Accuracy: 49.44%\nEpoch [10/10], Loss: nan, Accuracy: 50.64%, Val Loss: nan, Val Accuracy: 49.44%\nTraining complete!\n","output_type":"stream"}]},{"cell_type":"code","source":"# Evaluate on the test set\ntest_loss, test_accuracy = evaluate_model(model, test_loader, criterion)\nprint(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%\")","metadata":{"execution":{"iopub.status.busy":"2024-09-05T16:42:20.047277Z","iopub.execute_input":"2024-09-05T16:42:20.048165Z","iopub.status.idle":"2024-09-05T16:42:20.462210Z","shell.execute_reply.started":"2024-09-05T16:42:20.048122Z","shell.execute_reply":"2024-09-05T16:42:20.461197Z"},"trusted":true},"execution_count":58,"outputs":[{"name":"stdout","text":"Test Loss: nan, Test Accuracy: 50.85%\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.save(model, 'ModelV0.pth')","metadata":{"execution":{"iopub.status.busy":"2024-09-05T17:13:53.706906Z","iopub.execute_input":"2024-09-05T17:13:53.707805Z","iopub.status.idle":"2024-09-05T17:13:53.807127Z","shell.execute_reply.started":"2024-09-05T17:13:53.707763Z","shell.execute_reply":"2024-09-05T17:13:53.806134Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}